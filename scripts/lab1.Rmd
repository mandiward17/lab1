
---
title: "Lab1-collab"
author: "Mandi Ward, Zach Farley, and Esme Castro"
date: "1/9/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(rio)
library(here)
library(tidyverse)
library(ggplot2)
library(cowplot)
library(tidytext)
rstats <- import(here("data", "rstats_tweets.rds"))
```

```{r, data-exploring}
# Histograms
ggplot(rstats, aes(x = display_text_width)) +
  geom_histogram(fill = "#036600",
                 color = "black",
                 alpha = 0.7,
                 bins = 50) +           # 50 bins
  theme_minimal()

ggplot(rstats, aes(x = display_text_width)) +
  geom_histogram(fill = "#036600",
                 color = "black",
                 alpha = 0.7,
                 bins = 250) +         # 250 bins
  theme_minimal()

ggplot(rstats, aes(x = display_text_width)) +
  geom_histogram(fill = "#036600",
                 color = "black",
                 alpha = 0.7,
                 bins = 25) +         # 25 bins
  theme_minimal()

ggplot(rstats, aes(x = display_text_width)) +
  geom_histogram(fill = "#036600",
                 color = "black",
                 alpha = 0.7,
                 bins = 15) +         # 15 bins
  theme_minimal()

## We think that the code wit 25 bins displays the data the best as we can see
## what looks to start as a normal distribution but then tapers off at the end. This
## visual shows the audience that there are not many tweets with text width greater than 150.

# Density Plot
ggplot(rstats, aes(display_text_width)) +
  geom_density(fill = "#532555", 
               bw = 25) +
  theme_minimal() +
  xlab("Text Width") +
  ylab("Density")
```

```{r look-for-plot}
#Proportion of rows containing "plot|Plot"
plot <- grepl("plot|Plot", rstats$text)
sum(plot)
```
Proportion of rows including the word "plot|Plot" = 29278/429513 = 0.068 (6.8%)

```{r}
tidy_text <- rstats %>% 
  unnest_tokens(word, text)

tidy_text %>% 
  count(word, sort = TRUE) #initial count of tidy_text dataset

tidy_text %>% 
  count(word, sort = TRUE) %>% 
  mutate(word = fct_reorder(word, n)) %>% 
  slice(1:15) %>%
  ggplot(aes(n, word)) +
    geom_col(fill = "cornflowerblue") #plot of top 15 most common words in tidy_text

tidy_text %>% 
  anti_join(stop_words) %>%
  count(word, sort = TRUE) %>% 
  mutate(word = fct_reorder(word, n)) %>% 
  slice(1:15) %>% 
  ggplot(aes(n, word)) +
  geom_col(fill = "blue") #plot of top 15 most common words in tidy_text, minus stop words

tidy_text2 <- tidy_text %>% filter(!word %in% c("t.co", "https", "http", "rt", "rstats")) #removed rows where unnecessary words are not needed

tidy_text2 %>% 
  anti_join(stop_words) %>% 
  count(word, sort = TRUE) %>% 
  mutate(word = fct_reorder(word, n)) %>% 
  slice(1:15) %>% 
  ggplot(aes(n, word)) +
  geom_col(fill = "blue") #plot of top 15 words minus stop words and unnecessary words
```

```{r stylized-plot}

tidy_text2 %>% 
  anti_join(stop_words) %>% 
  count(word, sort = TRUE) %>% 
  mutate(word = fct_reorder(word, n)) %>% 
  slice(1:15) %>% 
  ggplot(aes(n, word)) +
  geom_col(fill = "blue", alpha = 0.5) +
  theme_minimal_grid() +
  labs(title = "Word frequencies in posts",
       subtitle = "Top 15 words displayed",
       x = "Count",
       y = "Word",
       caption = "Data from Mike Kearny, distributed via #tidytuesday")
```





